# -*- coding: utf-8 -*-
"""
é«˜é¢‘è®¢å•å› å­è®¡ç®—ï¼ˆå‡å€¼ç‰ˆï¼‰
"""
import os
import time as tm
import itertools
import warnings
from datetime import time, datetime
from typing import Optional
import pandas as pd
import numpy as np
from joblib import Parallel, delayed, parallel_backend
import pyarrow.parquet as pq

warnings.filterwarnings('ignore')

# -------------------- 1. å‚æ•° --------------------
DEBUG = False
AUCTION_AM = (time(9, 15), time(9, 25))
FINAL_CALL = (time(9, 25), time(9, 30))
CONT_AM = (time(9, 30), time(11, 30))
NOON_BREAK = (time(11, 30), time(13, 0))
CONT_PM = (time(13, 0), time(14, 57))
MORNING_END_INCLUSIVE = time(11, 30)     # åŒ…å«ä¸Šåˆç»“æŸæ—¶é—´ 11:30:00
AFTERNOON_START_INCLUSIVE = time(13, 0)

# -------------------- 2. å·¥å…· --------------------
def calc_effective_duration_vec(start: pd.Series, end: pd.Series) -> np.ndarray:
    start, end = pd.to_datetime(start), pd.to_datetime(end)
    day = start.dt.normalize()
    am_end, pm_start = day + pd.Timedelta("11:30:00"), day + pd.Timedelta("13:00:00")
    no_span = (end <= am_end) | (start >= pm_start)
    dur_no_span = (end - start).dt.total_seconds()
    dur_morning = (am_end - start).dt.total_seconds().clip(lower=0)
    dur_afternoon = (end - pm_start).dt.total_seconds().clip(lower=0)
    dur_span = dur_morning + dur_afternoon
    return np.where(no_span, dur_no_span, dur_span)


def calculate_threshold_mean_std(s: pd.Series) -> float:
    """è®¡ç®—é˜ˆå€¼ï¼šå‡å€¼+æ ‡å‡†å·®"""
    if len(s) < 2:
        return s.max() if len(s) else 0.0
    mean, std = s.mean(), s.std()
    return mean if std == 0 else mean + std


# -------------------- 3. å•æ—¥å•è‚¡ --------------------
def one_day_stock_factor(secucode: str, date: str, df: pd.DataFrame) -> Optional[dict]:
    """å¤„ç†å•æ—¥å•åªè‚¡ç¥¨çš„é«˜é¢‘è®¢å•å› å­"""
    total_volume = df["Volume"].sum()
    if total_volume == 0:
        return None

    # 3.1 ä¹°å•èšåˆ
    buy = (df.groupby("BuyOrderID")
           .agg(buy_volume=("Volume", "sum"),
                buy_first_time=("TradeTime", "min"),
                buy_last_time=("TradeTime", "max"))
           .reset_index())
    buy["buy_duration"] = calc_effective_duration_vec(buy["buy_first_time"], buy["buy_last_time"])

    # 3.2 å–å•èšåˆ
    sell = (df.groupby("SaleOrderID")
            .agg(sell_volume=("Volume", "sum"),
                 sell_first_time=("TradeTime", "min"),
                 sell_last_time=("TradeTime", "max"))
            .reset_index())
    sell["sell_duration"] = calc_effective_duration_vec(sell["sell_first_time"], sell["sell_last_time"])

    # 3.3 é˜ˆå€¼è®¡ç®—
    buy_big_thr = calculate_threshold_mean_std(buy["buy_volume"])
    sell_big_thr = calculate_threshold_mean_std(sell["sell_volume"])
    buy_long_thr = calculate_threshold_mean_std(buy["buy_duration"])
    sell_long_thr = calculate_threshold_mean_std(sell["sell_duration"])

    df = (df.merge(buy[["BuyOrderID", "buy_volume", "buy_duration"]], how="left", on="BuyOrderID")
          .merge(sell[["SaleOrderID", "sell_volume", "sell_duration"]], how="left", on="SaleOrderID"))
    df[["buy_volume", "sell_volume", "buy_duration", "sell_duration"]] = \
        df[["buy_volume", "sell_volume", "buy_duration", "sell_duration"]].fillna(0)

    # 3.4 æ ‡è®°
    df["is_big_buy"] = df["buy_volume"] > buy_big_thr
    df["is_big_sell"] = df["sell_volume"] > sell_big_thr
    df["is_long_buy"] = df["buy_duration"] > buy_long_thr
    df["is_long_sell"] = df["sell_duration"] > sell_long_thr

    # 3.5 å­å› å­è®¡ç®—
    def vol_ratio(mask):
        return df.loc[mask, "Volume"].sum() / total_volume if mask.any() else 0.0

    bb_ns = vol_ratio(df["is_big_buy"] & ~df["is_big_sell"])
    nb_bs = vol_ratio(~df["is_big_buy"] & df["is_big_sell"])
    bb_bs = vol_ratio(df["is_big_buy"] & df["is_big_sell"])
    lb_nls = vol_ratio(df["is_long_buy"] & ~df["is_long_sell"])
    nb_ls = vol_ratio(~df["is_long_buy"] & df["is_long_sell"])
    lb_ls = vol_ratio(df["is_long_buy"] & df["is_long_sell"])

    # 3.6 æ ¸å¿ƒå› å­
    vol_big_orig = bb_ns + nb_bs + 2 * bb_bs
    vol_big = -bb_ns - nb_bs + bb_bs
    vol_long = lb_nls + nb_ls + 2 * lb_ls
    vol_long_big = vol_big + vol_long

    # 3.7 16ç±»è®¢å•
    order_type = {}
    for bb, bs, lb, ls in itertools.product([0, 1], repeat=4):
        mask = (df["is_big_buy"].eq(bool(bb)) &
                df["is_big_sell"].eq(bool(bs)) &
                df["is_long_buy"].eq(bool(lb)) &
                df["is_long_sell"].eq(bool(ls)))
        order_type[f"BB{bb}_BS{bs}_LB{lb}_LS{ls}"] = vol_ratio(mask)

    select = np.mean([order_type["BB1_BS1_LB1_LS1"],
                      order_type["BB1_BS1_LB0_LS1"],
                      order_type["BB1_BS1_LB1_LS0"],
                      order_type["BB0_BS1_LB0_LS1"],
                      -order_type["BB1_BS0_LB0_LS0"]])

    # 3.8 è¿”å›ç»“æœ
    return dict(
        secucode=secucode,
        date=date,
        total_volume=total_volume,
        total_trades=len(df),
        buy_orders=len(buy),
        sell_orders=len(sell),
        buy_big_threshold=buy_big_thr,
        sell_big_threshold=sell_big_thr,
        buy_long_threshold=buy_long_thr,
        sell_long_threshold=sell_long_thr,
        big_buy_non_big_sell=bb_ns,
        non_big_buy_big_sell=nb_bs,
        big_buy_big_sell=bb_bs,
        long_buy_non_long_sell=lb_nls,
        non_long_buy_long_sell=nb_ls,
        long_buy_long_sell=lb_ls,
        VolumeBigOrigin=vol_big_orig,
        VolumeBig=vol_big,
        VolumeLong=vol_long,
        VolumeLongBig=vol_long_big,
        VolumeLongBigSelect=select,
        **order_type)


# -------------------- 4. ä¸»æ§--------------------
def calculate_all_hfa_factors(data_path: str, output_dir: str = None):
    """ä¸»è®¡ç®—å‡½æ•° """
    timings = {}

    # 4.1 åˆ—è£å‰ª + å†…å­˜ä¼˜åŒ–
    t0_start = tm.time()
    columns_needed = ["secucode", "date", "Time", "Volume", "BuyOrderID", "SaleOrderID"]
    table = pq.read_table(data_path, columns=columns_needed, memory_map=True)
    df = table.to_pandas()
    timings['æ•°æ®åŠ è½½'] = tm.time() - t0_start
    print(f"   æ•°æ®åŠ è½½è€—æ—¶: {timings['æ•°æ®åŠ è½½']:.2f}s ï¼Œå½¢çŠ¶: {df.shape}")

    # 4.2 ä¼˜åŒ–æ—¶é—´å¤„ç†
    print(f"\n   ğŸš€ ä¼˜åŒ–æ—¶é—´å¤„ç†ï¼ˆé¿å…å­—ç¬¦ä¸²è½¬æ¢ï¼‰")
    t1_start = tm.time()

    # æ£€æŸ¥æ•°æ®ç±»å‹
    print(f"      dateåˆ—ç±»å‹: {df['date'].dtype}, Timeåˆ—ç±»å‹: {df['Time'].dtype}")

    # ç›´æ¥æ•°å€¼è¿ç®—
    try:
        df['TradeTime'] = df['date'] + (df['Time'] - df['Time'].dt.normalize())
        print(f"      ä½¿ç”¨ç›´æ¥æ•°å€¼è¿ç®—åˆå¹¶æ—¶é—´")
    except Exception as e:
        #å¤‡ç”¨æ–¹æ¡ˆï¼ˆå¦‚æœéœ€è¦å¤„ç†æ ¼å¼é—®é¢˜ï¼‰
        print(f"      æ–¹æ³•1å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {e}")
        df['TradeTime'] = pd.to_datetime(
            df['date'].dt.date.astype(str) + ' ' + df['Time'].dt.time.astype(str),
            format='%Y-%m-%d %H:%M:%S.%f',
            errors='coerce'
        )

    if df['TradeTime'].isna().any():
        print(f"      âš ï¸  è­¦å‘Š: {df['TradeTime'].isna().sum()} æ¡è®°å½•æ—¶é—´è½¬æ¢å¤±è´¥")
        df = df.dropna(subset=['TradeTime']).copy()

    # æå–æ—¶é—´éƒ¨åˆ†å¹¶è¿‡æ»¤
    df['time_only'] = df['TradeTime'].dt.time
    mask = (((df["time_only"] >= CONT_AM[0]) & (df["time_only"] <= MORNING_END_INCLUSIVE)) |
            ((df["time_only"] >= AFTERNOON_START_INCLUSIVE ) & (df["time_only"] < CONT_PM[1])))
    df = df[mask].copy()

    timings['æ—¶é—´å¤„ç†è¿‡æ»¤'] = tm.time() - t1_start
    print(f"   æ—¶é—´å¤„ç†+è¿‡æ»¤è€—æ—¶: {timings['æ—¶é—´å¤„ç†è¿‡æ»¤']:.2f}s ï¼Œè¿ç»­ç«ä»·è®°å½•: {len(df):,}")

    # 4.3 ä¼˜åŒ–åˆ†ç»„å‡†å¤‡
    print(f"\n   ğŸš€ ä¼˜åŒ–åˆ†ç»„å‡†å¤‡ï¼ˆé¿å…å­—ç¬¦ä¸²è½¬æ¢ï¼‰")
    t2_start = tm.time()

    df = df.sort_values(["secucode", "date"]).reset_index(drop=True)
    groups = []
    group_count = 0

    for (stk, date_val), sub in df.groupby(["secucode", "date"], sort=False):
        date_str = date_val.strftime('%Y%m%d')
        groups.append((stk, date_str, sub[["TradeTime", "Volume", "BuyOrderID", "SaleOrderID"]].copy()))
        group_count += 1

    timings['åˆ†ç»„å‡†å¤‡'] = tm.time() - t2_start
    print(f"   åˆ†ç»„å‡†å¤‡è€—æ—¶: {timings['åˆ†ç»„å‡†å¤‡']:.2f}s ï¼Œä»»åŠ¡æ•°: {len(groups)}")

    # 4.4 å¹¶è¡Œè®¡ç®—
    t3_start = tm.time()
    n_tasks = len(groups)
    n_jobs = min(os.cpu_count(), n_tasks, 28)
    print(f"\n   âš¡ ä½¿ç”¨ {n_jobs} ä¸ªè¿›ç¨‹è¿›è¡Œå¹¶è¡Œè®¡ç®—")

    with parallel_backend('loky', n_jobs=n_jobs):
        results = Parallel(verbose=10, batch_size='auto', max_nbytes='1M')(
            delayed(one_day_stock_factor)(stk, d, sub)
            for stk, d, sub in groups
        )

    results = [r for r in results if r is not None]
    timings['å¹¶è¡Œè®¡ç®—'] = tm.time() - t3_start
    print(f"   å¹¶è¡Œè®¡ç®—è€—æ—¶: {timings['å¹¶è¡Œè®¡ç®—']:.2f}s ï¼Œæœ‰æ•ˆç»“æœ: {len(results)}")

    # 4.5 ç»“æœä¿å­˜
    t4_start = tm.time()
    if results:
        factors_df = pd.DataFrame(results)

        if output_dir:
            os.makedirs(output_dir, exist_ok=True)
            out_path = os.path.join(output_dir, "é«˜é¢‘è®¢å•å› å­_ä¼˜åŒ–ç‰ˆ.feather")
            factors_df.reset_index(drop=True).to_feather(out_path)

            csv_path = os.path.join(output_dir, "é«˜é¢‘è®¢å•å› å­_ä¼˜åŒ–ç‰ˆ.csv")
            factors_df.to_csv(csv_path, index=False, encoding='utf-8-sig')

            timings['ç»“æœä¿å­˜'] = tm.time() - t4_start

            print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜ -> {out_path}")
            print(f"   åŒæ—¶ä¿å­˜ä¸ºCSV -> {csv_path}")
            print(f"   ç»“æœä¿å­˜è€—æ—¶: {timings['ç»“æœä¿å­˜']:.2f}s")
            print(f"   ç»“æœå½¢çŠ¶: {factors_df.shape}")

        return factors_df, timings
    else:
        print("âš ï¸  æ²¡æœ‰æœ‰æ•ˆç»“æœ")
        return pd.DataFrame(), timings


# -------------------- 5. å…¥å£ --------------------
if __name__ == "__main__":
    prog_start = tm.time()
    print(f"ç¨‹åºå¼€å§‹: {datetime.now():%F %T}")

    DATA = r"D:/pycharm/pythonProject/dataExample_5k.parquet"
    OUT_DIR = r"D:/pycharm/pythonProject"

    # è¿è¡Œä¸»ç¨‹åº
    df_fac, timings = calculate_all_hfa_factors(DATA, OUT_DIR)

    total_time = tm.time() - prog_start

    print(f"\n" + "=" * 80)
    print("ğŸ“ˆ æ€§èƒ½åˆ†ææŠ¥å‘Š")
    print("=" * 80)

    # æ±‡æ€»æ‰€æœ‰è€—æ—¶
    print(f"\næ€»è¿è¡Œæ—¶é—´: {total_time:.3f}ç§’")
    print(f"ç¨‹åºå¼€å§‹: {datetime.fromtimestamp(prog_start):%F %T}")
    print(f"ç¨‹åºç»“æŸ: {datetime.now():%F %T}")

    print(f"\nå„é˜¶æ®µè€—æ—¶è¯¦æƒ…:")
    print("-" * 60)

    # æŒ‰é˜¶æ®µåˆ†ç±»æ˜¾ç¤º
    stage_times = {
        'æ•°æ®åŠ è½½': timings.get('æ•°æ®åŠ è½½', 0),
        'æ—¶é—´å¤„ç†è¿‡æ»¤': timings.get('æ—¶é—´å¤„ç†è¿‡æ»¤', 0),
        'åˆ†ç»„å‡†å¤‡': timings.get('åˆ†ç»„å‡†å¤‡', 0),
        'å¹¶è¡Œè®¡ç®—': timings.get('å¹¶è¡Œè®¡ç®—', 0),
        'ç»“æœä¿å­˜': timings.get('ç»“æœä¿å­˜', 0)
    }

    for stage_name, stage_time in stage_times.items():
        if stage_time > 0:
            percentage = (stage_time / total_time) * 100
            print(f"{stage_name}: {stage_time:.3f}s ({percentage:.1f}%)")

    # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
    if not df_fac.empty:
        print(f"\nğŸ“‹ è®¡ç®—ç»“æœé¢„è§ˆ (å‰5è¡Œ):")
        print(df_fac[['secucode', 'date', 'total_volume', 'total_trades', 'VolumeBig', 'VolumeLong',
                      'VolumeLongBig']].head())