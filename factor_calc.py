# -*- coding: utf-8 -*-
"""
é«˜é¢‘è®¢å•å› å­è®¡ç®— - å•æ—¥ç‰ˆ
æ ¸å¿ƒåŠŸèƒ½ï¼šå¤„ç†å•æ—¥è‚¡ç¥¨é«˜é¢‘äº¤æ˜“æ•°æ®ï¼Œè®¡ç®—è®¢å•è¡Œä¸ºç‰¹å¾å› å­
ä¼˜åŒ–ç‰¹ç‚¹ï¼š
1. ä¸ä½¿ç”¨dateåˆ—ï¼ˆå› ä¸ºæ‰€æœ‰æ•°æ®éƒ½æ˜¯åŒä¸€å¤©ï¼‰
2. è¾“å‡ºCSVå’ŒParquetæ ¼å¼
"""
import os
import time as tm
import warnings
from datetime import time, datetime
from typing import Optional
import pandas as pd
import numpy as np
import pyarrow.parquet as pq

warnings.filterwarnings('ignore')

# -------------------- 1. å…¨å±€å‚æ•°å®šä¹‰ --------------------
CONT_AM = (time(9, 30), time(11, 30))  # ä¸Šåˆè¿ç»­ç«ä»·æ—¶é—´æ®µ
CONT_PM = (time(13, 0), time(14, 57))  # ä¸‹åˆè¿ç»­ç«ä»·æ—¶é—´æ®µ


# -------------------- 2. æ ¸å¿ƒè®¡ç®—å‡½æ•° --------------------
def compute_factors_ultimate_single_day(secucode: str, target_date: str, df: pd.DataFrame) -> Optional[dict]:
    """
    å•æ—¥ä¼˜åŒ–ç‰ˆå› å­è®¡ç®—å‡½æ•°

    åŠŸèƒ½ï¼šè®¡ç®—è‚¡ç¥¨çš„é«˜é¢‘è®¢å•å› å­
    è¾“å…¥ï¼š
        secucode: è‚¡ç¥¨ä»£ç 
        target_date: äº¤æ˜“æ—¥æœŸï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼‰
        df: å•åªè‚¡ç¥¨çš„å•æ—¥äº¤æ˜“æ•°æ®
    è¾“å‡ºï¼š
        dict: åŒ…å«æ‰€æœ‰è®¡ç®—å› å­çš„å­—å…¸ï¼Œå¦‚æœæ•°æ®æ— æ•ˆè¿”å›None
    """
    # æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥ï¼šç©ºæ•°æ®æˆ–æˆäº¤é‡ä¸º0çš„æ•°æ®ç›´æ¥è·³è¿‡
    if df.empty or df["Volume"].sum() == 0:
        return None

    # æ€»æˆäº¤é‡ï¼šç”¨äºåç»­æ¯”ä¾‹è®¡ç®—
    total_volume = float(df["Volume"].sum())

    # -------------------- æ­¥éª¤1ï¼šè®¢å•èšåˆ --------------------
    # æŒ‰ä¹°æ–¹è®¢å•IDåˆ†ç»„ï¼Œè®¡ç®—æ¯ä¸ªä¹°å•çš„ç‰¹å¾
    # observed=Trueï¼šä¼˜åŒ–groupbyæ€§èƒ½ï¼Œå‡å°‘å†…å­˜ä½¿ç”¨
    buy = df.groupby("BuyOrderID", observed=True).agg(
        buy_volume=("Volume", "sum"),  # ä¹°å•æ€»æˆäº¤é‡
        buy_first_time=("TradeTime", "min"),  # ä¹°å•é¦–æ¬¡æˆäº¤æ—¶é—´
        buy_last_time=("TradeTime", "max")  # ä¹°å•æœ«æ¬¡æˆäº¤æ—¶é—´
    ).reset_index()

    # æŒ‰å–æ–¹è®¢å•IDåˆ†ç»„ï¼Œè®¡ç®—æ¯ä¸ªå–å•çš„ç‰¹å¾
    sell = df.groupby("SaleOrderID", observed=True).agg(
        sell_volume=("Volume", "sum"),  # å–å•æ€»æˆäº¤é‡
        sell_first_time=("TradeTime", "min"),  # å–å•é¦–æ¬¡æˆäº¤æ—¶é—´
        sell_last_time=("TradeTime", "max")  # å–å•æœ«æ¬¡æˆäº¤æ—¶é—´
    ).reset_index()

    # -------------------- æ­¥éª¤2ï¼šè®¡ç®—è®¢å•æŒç»­æ—¶é—´ --------------------
    def calc_duration_fast(start, end):
        """
        å¿«é€Ÿè®¡ç®—è®¢å•æŒç»­æ—¶é—´ï¼Œè€ƒè™‘åˆä¼‘æ—¶é—´æ‰£é™¤

        é€»è¾‘ï¼š
        1. è®¡ç®—åŸå§‹æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        2. å¦‚æœè®¢å•è·¨è¶Šåˆä¼‘ï¼ˆå¼€å§‹<11:30ä¸”ç»“æŸ>13:00ï¼‰ï¼Œæ‰£é™¤5400ç§’ï¼ˆ1.5å°æ—¶ï¼‰
        3. è¿”å›è°ƒæ•´åçš„æŒç»­æ—¶é—´
        """
        duration = (end - start).dt.total_seconds()
        spans_noon = (start.dt.hour < 12) & (end.dt.hour >= 13)
        return duration - spans_noon.astype(int) * 5400

    # è®¡ç®—ä¹°å•å’Œå–å•çš„æŒç»­æ—¶é—´
    buy["buy_duration"] = calc_duration_fast(buy["buy_first_time"], buy["buy_last_time"])
    sell["sell_duration"] = calc_duration_fast(sell["sell_first_time"], sell["sell_last_time"])

    # -------------------- æ­¥éª¤3ï¼šè®¡ç®—é˜ˆå€¼ï¼ˆ90%åˆ†ä½æ•°ï¼‰ --------------------
    def threshold_fast(series):
        """
        å¿«é€Ÿè®¡ç®—é˜ˆå€¼ï¼ˆ90%åˆ†ä½æ•°ï¼‰

        é€»è¾‘ï¼š
        1. æå–åºåˆ—å€¼
        2. å¦‚æœæ•°æ®å°‘äº2ä¸ªï¼Œè¿”å›å”¯ä¸€å€¼æˆ–0
        3. ä½¿ç”¨numpyçš„percentileè®¡ç®—90%åˆ†ä½æ•°ï¼Œæ¯”pandasæ›´å¿«
        """
        vals = series.values
        if len(vals) < 2:
            return float(vals[0]) if len(vals) == 1 else 0.0
        return float(np.percentile(vals[~np.isnan(vals)], 90))

    # è®¡ç®—4ä¸ªé˜ˆå€¼ï¼šå¤§ä¹°å•ã€å¤§å–å•ã€é•¿ä¹°å•ã€é•¿å–å•çš„é˜ˆå€¼
    buy_big_thr = threshold_fast(buy["buy_volume"])  # å¤§ä¹°å•æˆäº¤é‡é˜ˆå€¼
    sell_big_thr = threshold_fast(sell["sell_volume"])  # å¤§å–å•æˆäº¤é‡é˜ˆå€¼
    buy_long_thr = threshold_fast(buy["buy_duration"])  # é•¿ä¹°å•æŒç»­æ—¶é—´é˜ˆå€¼
    sell_long_thr = threshold_fast(sell["sell_duration"])  # é•¿å–å•æŒç»­æ—¶é—´é˜ˆå€¼

    # -------------------- æ­¥éª¤4ï¼šå°†è®¢å•ç‰¹å¾æ˜ å°„å›åŸå§‹æ•°æ® --------------------
    # åˆ›å»ºå­—å…¸æ˜ å°„ï¼šè®¢å•ID -> è®¢å•ç‰¹å¾ï¼ˆæ¯”mergeæ›´é«˜æ•ˆï¼‰
    buy_vol_map = dict(zip(buy["BuyOrderID"], buy["buy_volume"]))
    buy_dur_map = dict(zip(buy["BuyOrderID"], buy["buy_duration"]))
    sell_vol_map = dict(zip(sell["SaleOrderID"], sell["sell_volume"]))
    sell_dur_map = dict(zip(sell["SaleOrderID"], sell["sell_duration"]))

    # ä½¿ç”¨mapå‡½æ•°å¿«é€Ÿæ˜ å°„ï¼ˆå‘é‡åŒ–æ“ä½œï¼‰
    df["buy_volume"] = df["BuyOrderID"].map(buy_vol_map).fillna(0)
    df["sell_volume"] = df["SaleOrderID"].map(sell_vol_map).fillna(0)
    df["buy_duration"] = df["BuyOrderID"].map(buy_dur_map).fillna(0)
    df["sell_duration"] = df["SaleOrderID"].map(sell_dur_map).fillna(0)

    # -------------------- æ­¥éª¤5ï¼šæ ‡è®°å¤§å•å’Œé•¿å• --------------------
    # å¸ƒå°”æ ‡è®°ï¼šæ˜¯å¦ä¸ºå¤§äºé˜ˆå€¼çš„è®¢å•
    df["is_big_buy"] = df["buy_volume"] > buy_big_thr  # å¤§ä¹°å•æ ‡è®°
    df["is_big_sell"] = df["sell_volume"] > sell_big_thr  # å¤§å–å•æ ‡è®°
    df["is_long_buy"] = df["buy_duration"] > buy_long_thr  # é•¿ä¹°å•æ ‡è®°
    df["is_long_sell"] = df["sell_duration"] > sell_long_thr  # é•¿å–å•æ ‡è®°

    # -------------------- æ­¥éª¤6ï¼šè®¡ç®—16ç±»è®¢å•æ¯”ä¾‹å› å­ --------------------
    # ä½¿ç”¨äºŒè¿›åˆ¶ç¼–ç å°†4ä¸ªå¸ƒå°”æ ‡è®°è½¬æ¢ä¸º0-15çš„æ•´æ•°ï¼ˆ16ç§ç»„åˆï¼‰
    # ç¼–ç è§„åˆ™ï¼šis_big_buy(8) + is_big_sell(4) + is_long_buy(2) + is_long_sell(1)
    code = (df["is_big_buy"].astype(int) * 8 +
            df["is_big_sell"].astype(int) * 4 +
            df["is_long_buy"].astype(int) * 2 +
            df["is_long_sell"].astype(int))

    # æŒ‰ç¼–ç åˆ†ç»„ï¼Œè®¡ç®—æ¯ç±»è®¢å•çš„æˆäº¤é‡å æ€»æˆäº¤é‡çš„æ¯”ä¾‹
    grouped = df.groupby(code)["Volume"].sum() / total_volume

    # æ„å»º16ä¸ªè®¢å•ç±»å‹å› å­çš„å­—å…¸
    # å‘½åæ ¼å¼ï¼šBB{å¤§ä¹°å•æ ‡è®°}_BS{å¤§å–å•æ ‡è®°}_LB{é•¿ä¹°å•æ ‡è®°}_LS{é•¿å–å•æ ‡è®°}
    order_type = {}
    for i in range(16):
        # ä»ç¼–ç ä¸­æå–4ä¸ªæ ‡è®°
        bb = (i & 8) // 8  # æå–å¤§ä¹°å•æ ‡è®°ï¼ˆç¬¬4ä½ï¼‰
        bs = (i & 4) // 4  # æå–å¤§å–å•æ ‡è®°ï¼ˆç¬¬3ä½ï¼‰
        lb = (i & 2) // 2  # æå–é•¿ä¹°å•æ ‡è®°ï¼ˆç¬¬2ä½ï¼‰
        ls = i & 1  # æå–é•¿å–å•æ ‡è®°ï¼ˆç¬¬1ä½ï¼‰

        # è·å–è¯¥ç±»å‹çš„æ¯”ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä¸º0.0
        order_type[f"BB{bb}_BS{bs}_LB{lb}_LS{ls}"] = float(grouped.get(i, 0.0))

    # -------------------- æ­¥éª¤7ï¼šè®¡ç®—6ä¸ªå­å› å­ --------------------
    # ä»16ç±»è®¢å•ä¸­ç»„åˆå‡º6ä¸ªæœ‰æ„ä¹‰çš„å­å› å­

    # bb_ns: å¤§ä¹°å•éå¤§å–å•ï¼ˆç¼–ç 8-11ï¼šå¤§ä¹°å•=1ï¼Œå¤§å–å•=0ï¼‰
    bb_ns_codes = [8, 9, 10, 11]
    bb_ns = sum(grouped.get(c, 0.0) for c in bb_ns_codes)

    # nb_bs: éå¤§ä¹°å•å¤§å–å•ï¼ˆç¼–ç 4-7ï¼šå¤§ä¹°å•=0ï¼Œå¤§å–å•=1ï¼‰
    nb_bs_codes = [4, 5, 6, 7]
    nb_bs = sum(grouped.get(c, 0.0) for c in nb_bs_codes)

    # bb_bs: å¤§ä¹°å•å¤§å–å•ï¼ˆç¼–ç 12-15ï¼šå¤§ä¹°å•=1ï¼Œå¤§å–å•=1ï¼‰
    bb_bs_codes = [12, 13, 14, 15]
    bb_bs = sum(grouped.get(c, 0.0) for c in bb_bs_codes)

    # lb_nls: é•¿ä¹°å•éé•¿å–å•ï¼ˆé•¿ä¹°å•=1ï¼Œé•¿å–å•=0ï¼‰
    lb_nls_codes = [2, 3, 6, 7, 10, 11, 14, 15]
    lb_nls = sum(grouped.get(c, 0.0) for c in lb_nls_codes)

    # nb_ls: éé•¿ä¹°å•é•¿å–å•ï¼ˆé•¿ä¹°å•=0ï¼Œé•¿å–å•=1ï¼‰
    nb_ls_codes = [1, 5, 9, 13]
    nb_ls = sum(grouped.get(c, 0.0) for c in nb_ls_codes)

    # lb_ls: é•¿ä¹°å•é•¿å–å•ï¼ˆé•¿ä¹°å•=1ï¼Œé•¿å–å•=1ï¼‰
    lb_ls_codes = [3, 7, 11, 15]
    lb_ls = sum(grouped.get(c, 0.0) for c in lb_ls_codes)

    # -------------------- æ­¥éª¤8ï¼šè®¡ç®—4ä¸ªæ ¸å¿ƒå› å­ --------------------
    # VolumeBigOrigin: å¤§å•åŸå§‹æ¯”ä¾‹ï¼ˆåŠ æƒè®¡ç®—ï¼‰
    vol_big_orig = bb_ns + nb_bs + 2 * bb_bs

    # VolumeBig: å¤§å•å‡€æµå‘å› å­ï¼ˆå¤šå¤´ä¸ºæ­£ï¼Œç©ºå¤´ä¸ºè´Ÿï¼‰
    vol_big = -bb_ns - nb_bs + bb_bs

    # VolumeLong: é•¿å•å‡€æµå‘å› å­
    vol_long = lb_nls + nb_ls + 2 * lb_ls

    # VolumeLongBig: é•¿å•å¤§å•ç»¼åˆå› å­
    vol_long_big = vol_big + vol_long

    # -------------------- æ­¥éª¤9ï¼šæ„å»ºè¿”å›ç»“æœ --------------------
    return {
        # åŸºæœ¬ä¿¡æ¯
        "secucode": secucode,  # è‚¡ç¥¨ä»£ç 
        "date": target_date,  # äº¤æ˜“æ—¥æœŸ
        "total_volume": total_volume,  # æ€»æˆäº¤é‡
        "total_trades": len(df),  # æ€»äº¤æ˜“ç¬”æ•°
        "buy_orders": len(buy),  # ä¹°å•æ•°é‡
        "sell_orders": len(sell),  # å–å•æ•°é‡

        # é˜ˆå€¼ä¿¡æ¯
        "buy_big_threshold": buy_big_thr,  # å¤§ä¹°å•é˜ˆå€¼
        "sell_big_threshold": sell_big_thr,  # å¤§å–å•é˜ˆå€¼
        "buy_long_threshold": buy_long_thr,  # é•¿ä¹°å•é˜ˆå€¼
        "sell_long_threshold": sell_long_thr,  # é•¿å–å•é˜ˆå€¼

        # 6ä¸ªå­å› å­
        "big_buy_non_big_sell": bb_ns,  # å¤§ä¹°å•éå¤§å–å•æ¯”ä¾‹
        "non_big_buy_big_sell": nb_bs,  # éå¤§ä¹°å•å¤§å–å•æ¯”ä¾‹
        "big_buy_big_sell": bb_bs,  # å¤§ä¹°å•å¤§å–å•æ¯”ä¾‹
        "long_buy_non_long_sell": lb_nls,  # é•¿ä¹°å•éé•¿å–å•æ¯”ä¾‹
        "non_long_buy_long_sell": nb_ls,  # éé•¿ä¹°å•é•¿å–å•æ¯”ä¾‹
        "long_buy_long_sell": lb_ls,  # é•¿ä¹°å•é•¿å–å•æ¯”ä¾‹

        # 4ä¸ªæ ¸å¿ƒå› å­
        "VolumeBigOrigin": vol_big_orig,  # å¤§å•åŸå§‹æ¯”ä¾‹
        "VolumeBig": vol_big,  # å¤§å•å‡€æµå‘å› å­
        "VolumeLong": vol_long,  # é•¿å•å‡€æµå‘å› å­
        "VolumeLongBig": vol_long_big,  # é•¿å•å¤§å•ç»¼åˆå› å­

        # 16ä¸ªè®¢å•ç±»å‹å› å­ï¼ˆå±•å¼€åˆ°å­—å…¸ä¸­ï¼‰
        **order_type
    }


# -------------------- 3. ä¸»å‡½æ•° --------------------
def calculate_factors_single_day_complete(data_path: str, target_date: str, output_dir: str = None):
    """
    ä¸»å‡½æ•°ï¼šå•æ—¥æ•°æ®å®Œæ•´å› å­è®¡ç®—æµç¨‹

    åŠŸèƒ½ï¼šç»„ç»‡å®Œæ•´çš„å› å­è®¡ç®—æµç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®åŠ è½½ã€é¢„å¤„ç†ã€è®¡ç®—å’Œä¿å­˜
    è¾“å…¥ï¼š
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆParquetæ ¼å¼ï¼‰
        target_date: ç›®æ ‡æ—¥æœŸï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼Œå¦‚"2024-01-15"ï¼‰
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„
    è¾“å‡ºï¼š
        tuple: (ç»“æœDataFrame, å„é˜¶æ®µè€—æ—¶å­—å…¸)
    """
    print("=" * 80)
    print("ğŸ“Š é«˜é¢‘è®¢å•å› å­è®¡ç®— - å•æ—¥å®Œæ•´ç‰ˆ")
    print(f"ğŸ“… ç›®æ ‡æ—¥æœŸ: {target_date}")
    print("âš¡ ç‰¹ç‚¹ï¼šä¸ä½¿ç”¨dateåˆ—ï¼Œç”¨16ä¸ªå› å­æ›¿æ¢selectå› å­")
    print("=" * 80)

    timings = {}  # è®°å½•å„é˜¶æ®µè€—æ—¶

    # -------------------- é˜¶æ®µ1ï¼šæ•°æ®åŠ è½½ --------------------
    t0 = tm.time()
    print("\n   1. æ•°æ®åŠ è½½...")

    # ä»…è¯»å–å¿…è¦çš„åˆ—ï¼ˆä¸åŒ…å«dateåˆ—ï¼‰
    columns_needed = ["secucode", "Time", "Volume", "BuyOrderID", "SaleOrderID"]
    df = pq.read_table(data_path, columns=columns_needed).to_pandas()

    timings['æ•°æ®åŠ è½½'] = tm.time() - t0
    print(f"      âœ“ è€—æ—¶: {timings['æ•°æ®åŠ è½½']:.1f}s, è®°å½•æ•°: {len(df):,}")

    # -------------------- é˜¶æ®µ2ï¼šæ—¶é—´å¤„ç†ä¸è¿‡æ»¤ --------------------
    t1 = tm.time()
    print("   2. æ—¶é—´å¤„ç†ä¸è¿‡æ»¤...")

    # è½¬æ¢Timeåˆ—ä¸ºdatetimeæ ¼å¼ï¼ˆåŸå§‹æ•°æ®å¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼‰
    df['Time'] = pd.to_datetime(df['Time'])

    # åˆ›å»ºåŸºç¡€æ—¥æœŸæ—¶é—´æˆ³ï¼ˆä½¿ç”¨ä¼ å…¥çš„target_dateï¼‰
    base_date = pd.to_datetime(target_date)

    # åˆå¹¶æ—¶é—´ï¼šå°†åŸºç¡€æ—¥æœŸä¸æ—¶é—´éƒ¨åˆ†ç»„åˆæˆå®Œæ•´çš„æ—¶é—´æˆ³
    df['TradeTime'] = base_date + (df['Time'] - df['Time'].dt.normalize())

    # è·å–æ—¶é—´éƒ¨åˆ†ï¼ˆç”¨äºè¿‡æ»¤ï¼‰
    time_only = df['TradeTime'].dt.time

    # æ ‡è®°éœ€è¦è°ƒæ•´çš„æ—¶é—´ç‚¹
    mask_pre = time_only < time(9, 30)  # æ—©äº9:30
    mask_noon = (time_only > time(11, 30)) & (time_only < time(13, 0))  # åˆä¼‘æ—¶é—´
    mask_close = time_only >= time(14, 57)  # æ”¶ç›˜å

    # è°ƒæ•´éè¿ç»­ç«ä»·æ—¶é—´åˆ°æœ€è¿‘çš„è¿ç»­ç«ä»·æ—¶é—´
    df.loc[mask_pre, 'TradeTime'] = base_date + pd.Timedelta(hours=9, minutes=30)
    df.loc[mask_noon, 'TradeTime'] = base_date + pd.Timedelta(hours=13, minutes=0)
    df.loc[mask_close, 'TradeTime'] = base_date + pd.Timedelta(hours=14, minutes=57)

    # é‡æ–°è·å–è°ƒæ•´åçš„æ—¶é—´
    time_only = df['TradeTime'].dt.time

    # è¿‡æ»¤ï¼šåªä¿ç•™è¿ç»­ç«ä»·æ—¶é—´æ®µçš„æ•°æ®
    mask = ((time_only >= time(9, 30)) & (time_only <= time(11, 30))) | \
           ((time_only >= time(13, 0)) & (time_only < time(14, 57)))
    df = df[mask].copy()  # ä½¿ç”¨copyé¿å…SettingWithCopyWarning

    timings['æ—¶é—´å¤„ç†è¿‡æ»¤'] = tm.time() - t1
    print(f"      âœ“ è€—æ—¶: {timings['æ—¶é—´å¤„ç†è¿‡æ»¤']:.1f}s, è¿‡æ»¤å: {len(df):,}")

    # -------------------- é˜¶æ®µ3ï¼šåˆ†ç»„å‡†å¤‡ --------------------
    t2 = tm.time()
    print("   3. åˆ†ç»„å‡†å¤‡...")

    groups = []
    # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„ï¼ˆå› ä¸ºæ˜¯å•æ—¥æ•°æ®ï¼Œä¸éœ€è¦å†æŒ‰dateåˆ†ç»„ï¼‰
    for secucode, sub_df in df.groupby("secucode"):
        # åªä¿ç•™è®¡ç®—æ‰€éœ€çš„åˆ—ï¼Œå‡å°‘å†…å­˜å ç”¨
        groups.append((secucode, target_date, sub_df[["TradeTime", "Volume", "BuyOrderID", "SaleOrderID"]]))

    timings['åˆ†ç»„å‡†å¤‡'] = tm.time() - t2
    print(f"      âœ“ è€—æ—¶: {timings['åˆ†ç»„å‡†å¤‡']:.1f}s, åˆ†ç»„æ•°: {len(groups):,}")

    # -------------------- é˜¶æ®µ4ï¼šå› å­è®¡ç®— --------------------
    t3 = tm.time()
    print("   4. å› å­è®¡ç®—...")

    results = []  # å­˜å‚¨æ‰€æœ‰è‚¡ç¥¨çš„è®¡ç®—ç»“æœ
    total = len(groups)
    start_time = tm.time()  # ç”¨äºè¿›åº¦æ˜¾ç¤º

    # éå†æ¯åªè‚¡ç¥¨è¿›è¡Œè®¡ç®—
    for i, (stk, date_str, sub_df) in enumerate(groups):
        # è°ƒç”¨æ ¸å¿ƒè®¡ç®—å‡½æ•°
        result = compute_factors_ultimate_single_day(stk, date_str, sub_df)
        if result:
            results.append(result)

        # è¿›åº¦æ˜¾ç¤ºï¼ˆæ¯100åªè‚¡ç¥¨æˆ–æ¯5ç§’æ˜¾ç¤ºä¸€æ¬¡ï¼‰
        if (i + 1) % 100 == 0 or tm.time() - start_time >= 5:
            elapsed = tm.time() - t3
            progress = (i + 1) / total * 100
            # è®¡ç®—å‰©ä½™æ—¶é—´
            remaining = (elapsed / (i + 1)) * (total - i - 1) if i > 0 else 0

            print(f"        è¿›åº¦: {i + 1}/{total} ({progress:.1f}%) - "
                  f"å·²ç”¨: {elapsed:.1f}s - å‰©ä½™: {remaining:.1f}s")
            start_time = tm.time()

    timings['å› å­è®¡ç®—'] = tm.time() - t3
    print(f"      âœ“ è€—æ—¶: {timings['å› å­è®¡ç®—']:.1f}s, æœ‰æ•ˆç»“æœ: {len(results):,}")

    # -------------------- é˜¶æ®µ5ï¼šä¿å­˜ç»“æœ --------------------
    t4 = tm.time()
    if results:  # å¦‚æœæœ‰æœ‰æ•ˆç»“æœ
        # å°†ç»“æœåˆ—è¡¨è½¬æ¢ä¸ºDataFrame
        factors_df = pd.DataFrame(results)

        if output_dir:
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(output_dir, exist_ok=True)

            # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŒ…å«æ—¥æœŸï¼‰
            date_str_for_filename = target_date.replace('-', '')[:8]  # æ ¼å¼åŒ–ä¸ºYYYYMMDD
            base_filename = f"é«˜é¢‘è®¢å•å› å­_å•æ—¥å®Œæ•´_{date_str_for_filename}"

            # ä¿å­˜ä¸ºCSVæ ¼å¼ï¼ˆä¾¿äºäººå·¥æŸ¥çœ‹ï¼‰
            csv_path = os.path.join(output_dir, f"{base_filename}.csv")
            factors_df.to_csv(csv_path, index=False, encoding='utf-8-sig')

            # ä¿å­˜ä¸ºParquetæ ¼å¼ï¼ˆé«˜æ€§èƒ½äºŒè¿›åˆ¶æ ¼å¼ï¼Œä¾¿äºåç»­åˆ†æï¼‰
            parquet_path = os.path.join(output_dir, f"{base_filename}.parquet")
            factors_df.to_parquet(parquet_path, index=False)

            timings['ç»“æœä¿å­˜'] = tm.time() - t4

            # è¾“å‡ºä¿å­˜ä¿¡æ¯
            print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜:")
            print(f"   CSV: {csv_path}")
            print(f"   Parquet: {parquet_path}")
            print(f"   ç»“æœå½¢çŠ¶: {factors_df.shape}")
            print(f"   åˆ—æ•°: {len(factors_df.columns)}")

            # æ˜¾ç¤ºè¯¦ç»†çš„åˆ—ç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“Š è¾“å‡ºåˆ—ç»Ÿè®¡:")
            print(f"   åŸºæœ¬ä¿¡æ¯åˆ—: 7ä¸ª")
            print(f"   é˜ˆå€¼åˆ—: 4ä¸ª")
            print(f"   å­å› å­åˆ—: 6ä¸ª")
            print(f"   æ ¸å¿ƒå› å­åˆ—: 4ä¸ª")
            print(f"   è®¢å•ç±»å‹å› å­: 16ä¸ª")
            print(f"   æ€»åˆ—æ•°: {7 + 4 + 6 + 4 + 16}ä¸ª")

        return factors_df, timings

    # å¦‚æœæ²¡æœ‰ç»“æœï¼Œè¿”å›ç©ºçš„DataFrame
    return pd.DataFrame(), timings


# -------------------- 4. ç¨‹åºå…¥å£ --------------------
if __name__ == "__main__":
    # è®°å½•ç¨‹åºå¼€å§‹æ—¶é—´
    prog_start = tm.time()
    print(f"ç¨‹åºå¼€å§‹: {datetime.now():%F %T}")

    # ==================== é…ç½®å‚æ•° ====================
    # æ•°æ®æ–‡ä»¶è·¯å¾„
    DATA = r"D:/pycharm/pythonProject/dataExample.parquet"

    # è¾“å‡ºç›®å½•
    OUT_DIR = r"D:/pycharm/pythonProject"

    # ç›®æ ‡æ—¥æœŸï¼ˆæ ¹æ®å®é™…æ•°æ®è®¾ç½®ï¼‰
    TARGET_DATE = "2024-01-15"
    try:
        # æ‰§è¡Œå› å­è®¡ç®—
        df_fac, timings = calculate_factors_single_day_complete(
            data_path=DATA,
            target_date=TARGET_DATE,
            output_dir=OUT_DIR
        )

        # è®¡ç®—æ€»è¿è¡Œæ—¶é—´
        total_time = tm.time() - prog_start

        # è¾“å‡ºè¿è¡Œæ—¶é—´ç»Ÿè®¡
        print(f"\næ€»è¿è¡Œæ—¶é—´: {total_time:.3f}ç§’")
        print(f"ç¨‹åºå¼€å§‹: {datetime.fromtimestamp(prog_start):%F %T}")
        print(f"ç¨‹åºç»“æŸ: {datetime.now():%F %T}")

        # è¾“å‡ºå„é˜¶æ®µè€—æ—¶è¯¦æƒ…
        print(f"\nå„é˜¶æ®µè€—æ—¶è¯¦æƒ…:")
        print("-" * 60)
        for name, time_val in timings.items():
            if time_val > 0:
                percentage = (time_val / total_time) * 100
                print(f"{name}: {time_val:.3f}s ({percentage:.1f}%)")

        # å¦‚æœè®¡ç®—ç»“æœä¸ä¸ºç©ºï¼Œæ˜¾ç¤ºé¢„è§ˆå’Œç»Ÿè®¡ä¿¡æ¯
        if not df_fac.empty:
            print(f"\nğŸ“‹ è®¡ç®—ç»“æœé¢„è§ˆ (å‰3è¡Œ):")
            # é€‰æ‹©å…³é”®åˆ—è¿›è¡Œé¢„è§ˆ
            key_columns = ['secucode', 'date', 'total_volume', 'total_trades',
                           'VolumeBig', 'VolumeLong', 'VolumeLongBig']
            # æ‰¾å‡ºæ‰€æœ‰16ä¸ªè®¢å•ç±»å‹å› å­
            factor_columns = [col for col in df_fac.columns if col.startswith('BB')]
            # åˆå¹¶é¢„è§ˆåˆ—ï¼šå…³é”®åˆ— + å‰3ä¸ªè®¢å•ç±»å‹å› å­
            preview_cols = key_columns + factor_columns[:3]

            # æ˜¾ç¤ºå‰3è¡Œæ•°æ®
            print(df_fac[preview_cols].head(3))

            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“Š å› å­ç»Ÿè®¡:")
            print(f"   è‚¡ç¥¨æ•°é‡: {len(df_fac)}")
            print(f"   æ€»å› å­æ•°: {len(df_fac.columns)}")
            print(f"   16ä¸ªè®¢å•ç±»å‹å› å­: {len(factor_columns)}ä¸ª")

            # éªŒè¯ï¼šæ£€æŸ¥æ˜¯å¦åŒ…å«æ‰€æœ‰åº”æœ‰çš„å› å­
            expected_columns = [
                'secucode', 'date', 'total_volume', 'total_trades', 'buy_orders', 'sell_orders',
                'buy_big_threshold', 'sell_big_threshold', 'buy_long_threshold', 'sell_long_threshold',
                'big_buy_non_big_sell', 'non_big_buy_big_sell', 'big_buy_big_sell',
                'long_buy_non_long_sell', 'non_long_buy_long_sell', 'long_buy_long_sell',
                'VolumeBigOrigin', 'VolumeBig', 'VolumeLong', 'VolumeLongBig'
            ]

            # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±çš„å› å­
            missing = [col for col in expected_columns if col not in df_fac.columns]
            if missing:
                print(f"   âš ï¸  ç¼ºå°‘çš„åŸæœ‰å› å­: {missing}")
            else:
                print("   âœ… æ‰€æœ‰åŸæœ‰å› å­éƒ½åœ¨è¾“å‡ºä¸­")

    # å¼‚å¸¸å¤„ç†
    except Exception as e:
        print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")
        import traceback

        traceback.print_exc()